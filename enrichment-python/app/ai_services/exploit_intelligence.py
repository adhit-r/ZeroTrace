"""
Exploit Intelligence Service - Automated exploit intelligence and analysis
"""

import asyncio
import json
import logging
import os
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import aiohttp
import requests
from bs4 import BeautifulSoup

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ExploitIntelligenceService:
    """Service for automated exploit intelligence gathering and analysis"""
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = 3600  # 1 hour cache TTL
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'ZeroTrace-ExploitIntel/1.0'
        })
        
        # API endpoints and configurations
        self.exploit_db_url = "https://www.exploit-db.com/api"
        self.github_api_url = "https://api.github.com"
        self.cisa_kev_url = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
        
        # Rate limiting
        self.rate_limits = {
            'exploit_db': {'requests': 0, 'reset_time': 0},
            'github': {'requests': 0, 'reset_time': 0},
            'cisa': {'requests': 0, 'reset_time': 0}
        }
        self.max_requests_per_minute = 30
    
    async def _check_rate_limit(self, source: str) -> bool:
        """Check if we're within rate limits for the source"""
        current_time = time.time()
        rate_limit = self.rate_limits[source]
        
        # Reset counter if minute has passed
        if current_time > rate_limit['reset_time']:
            rate_limit['requests'] = 0
            rate_limit['reset_time'] = current_time + 60
        
        return rate_limit['requests'] < self.max_requests_per_minute
    
    async def _increment_rate_limit(self, source: str):
        """Increment rate limit counter for source"""
        self.rate_limits[source]['requests'] += 1
    
    async def _get_cached_data(self, cache_key: str) -> Optional[Dict]:
        """Get cached data if available and not expired"""
        if cache_key in self.cache:
            cached_data = self.cache[cache_key]
            if time.time() - cached_data['timestamp'] < self.cache_ttl:
                logger.debug(f"Returning cached data for {cache_key}")
                return cached_data['data']
            else:
                # Remove expired cache entry
                del self.cache[cache_key]
        return None
    
    async def _cache_data(self, cache_key: str, data: Dict):
        """Cache data with timestamp"""
        self.cache[cache_key] = {
            'data': data,
            'timestamp': time.time()
        }
        logger.debug(f"Cached data for {cache_key}")
    
    async def get_exploit_intelligence(self, cve_id: str, package_name: str = None) -> Dict:
        """
        Get comprehensive exploit intelligence for a CVE
        
        Args:
            cve_id: CVE identifier
            package_name: Optional package name for additional context
        
        Returns:
            Dict containing exploit intelligence data
        """
        cache_key = f"exploit_intel_{cve_id}_{package_name or 'none'}"
        
        # Check cache first
        cached_data = await self._get_cached_data(cache_key)
        if cached_data:
            return cached_data
        
        # Gather intelligence from multiple sources
        intelligence = {
            'cve_id': cve_id,
            'package_name': package_name,
            'exploit_availability': False,
            'exploit_sources': [],
            'exploit_complexity': 'unknown',
            'exploit_likelihood': 0.0,
            'public_exploits': [],
            'github_advisories': [],
            'cisa_kev': False,
            'threat_actors': [],
            'attack_vectors': [],
            'remediation_urgency': 'medium',
            'confidence_score': 0.0,
            'last_updated': datetime.utcnow().isoformat()
        }
        
        try:
            # Gather data from all sources concurrently
            tasks = [
                self._get_exploit_db_data(cve_id),
                self._get_github_advisories(cve_id, package_name),
                self._get_cisa_kev_data(cve_id),
                self._analyze_exploit_complexity(cve_id, package_name)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            exploit_db_data = results[0] if not isinstance(results[0], Exception) else {}
            github_data = results[1] if not isinstance(results[1], Exception) else []
            cisa_data = results[2] if not isinstance(results[2], Exception) else {}
            complexity_data = results[3] if not isinstance(results[3], Exception) else {}
            
            # Merge intelligence data
            intelligence.update(exploit_db_data)
            intelligence['github_advisories'] = github_data
            intelligence['cisa_kev'] = cisa_data.get('in_kev', False)
            
            if complexity_data:
                intelligence.update(complexity_data)
            
            # Calculate overall confidence score
            intelligence['confidence_score'] = self._calculate_confidence_score(intelligence)
            
            # Determine remediation urgency
            intelligence['remediation_urgency'] = self._determine_remediation_urgency(intelligence)
            
        except Exception as e:
            logger.error(f"Error gathering exploit intelligence: {e}")
            intelligence['error'] = str(e)
        
        # Cache the results
        await self._cache_data(cache_key, intelligence)
        
        return intelligence
    
    async def _get_exploit_db_data(self, cve_id: str) -> Dict:
        """Get exploit data from Exploit-DB"""
        if not await self._check_rate_limit('exploit_db'):
            logger.warning("Exploit-DB rate limit exceeded")
            return {}
        
        try:
            await self._increment_rate_limit('exploit_db')
            
            # Search for exploits related to the CVE
            search_url = f"{self.exploit_db_url}/search"
            params = {
                'cve': cve_id,
                'type': 'exploits'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(search_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        exploits = []
                        if 'data' in data:
                            for exploit in data['data']:
                                exploits.append({
                                    'id': exploit.get('id'),
                                    'title': exploit.get('title'),
                                    'description': exploit.get('description'),
                                    'date_published': exploit.get('date_published'),
                                    'verified': exploit.get('verified', False),
                                    'platform': exploit.get('platform'),
                                    'type': exploit.get('type'),
                                    'port': exploit.get('port')
                                })
                        
                        return {
                            'exploit_availability': len(exploits) > 0,
                            'public_exploits': exploits,
                            'exploit_count': len(exploits)
                        }
                    else:
                        logger.warning(f"Exploit-DB API returned status {response.status}")
                        return {}
                        
        except Exception as e:
            logger.error(f"Error fetching Exploit-DB data: {e}")
            return {}
    
    async def _get_github_advisories(self, cve_id: str, package_name: str = None) -> List[Dict]:
        """Get GitHub security advisories for the CVE"""
        if not await self._check_rate_limit('github'):
            logger.warning("GitHub rate limit exceeded")
            return []
        
        try:
            await self._increment_rate_limit('github')
            
            advisories = []
            
            # Search GitHub Security Advisories
            search_url = f"{self.github_api_url}/search/repositories"
            query = f"security advisory {cve_id}"
            if package_name:
                query += f" {package_name}"
            
            params = {
                'q': query,
                'sort': 'updated',
                'order': 'desc'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(search_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        for repo in data.get('items', [])[:5]:  # Limit to top 5 results
                            advisories.append({
                                'repository': repo.get('full_name'),
                                'description': repo.get('description'),
                                'updated_at': repo.get('updated_at'),
                                'stars': repo.get('stargazers_count'),
                                'url': repo.get('html_url')
                            })
            
            return advisories
            
        except Exception as e:
            logger.error(f"Error fetching GitHub advisories: {e}")
            return []
    
    async def _get_cisa_kev_data(self, cve_id: str) -> Dict:
        """Get CISA Known Exploited Vulnerabilities data"""
        if not await self._check_rate_limit('cisa'):
            logger.warning("CISA rate limit exceeded")
            return {}
        
        try:
            await self._increment_rate_limit('cisa')
            
            async with aiohttp.ClientSession() as session:
                async with session.get(self.cisa_kev_url) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # Check if CVE is in the KEV catalog
                        vulnerabilities = data.get('vulnerabilities', [])
                        for vuln in vulnerabilities:
                            if vuln.get('cveID') == cve_id:
                                return {
                                    'in_kev': True,
                                    'date_added': vuln.get('dateAdded'),
                                    'due_date': vuln.get('dueDate'),
                                    'required_action': vuln.get('requiredAction'),
                                    'vendor': vuln.get('vendorProject'),
                                    'product': vuln.get('product'),
                                    'short_description': vuln.get('shortDescription')
                                }
                        
                        return {'in_kev': False}
                    else:
                        logger.warning(f"CISA KEV API returned status {response.status}")
                        return {}
                        
        except Exception as e:
            logger.error(f"Error fetching CISA KEV data: {e}")
            return {}
    
    async def _analyze_exploit_complexity(self, cve_id: str, package_name: str = None) -> Dict:
        """Analyze exploit complexity and likelihood"""
        try:
            # This is a simplified analysis - in production, this would use ML models
            complexity_factors = {
                'remote_code_execution': 0.8,
                'privilege_escalation': 0.7,
                'buffer_overflow': 0.9,
                'sql_injection': 0.6,
                'cross_site_scripting': 0.4,
                'denial_of_service': 0.3
            }
            
            # Analyze based on CVE ID patterns and package name
            likelihood = 0.5  # Base likelihood
            
            if package_name:
                package_lower = package_name.lower()
                for factor, weight in complexity_factors.items():
                    if factor in package_lower:
                        likelihood = max(likelihood, weight)
            
            # Adjust based on CVE year (newer CVEs might be more likely to be exploited)
            cve_year = int(cve_id.split('-')[1]) if '-' in cve_id else 2020
            current_year = datetime.now().year
            
            if current_year - cve_year <= 2:
                likelihood += 0.2
            elif current_year - cve_year <= 5:
                likelihood += 0.1
            
            # Determine complexity level
            if likelihood >= 0.8:
                complexity = 'high'
            elif likelihood >= 0.6:
                complexity = 'medium'
            else:
                complexity = 'low'
            
            return {
                'exploit_complexity': complexity,
                'exploit_likelihood': min(likelihood, 1.0),
                'threat_level': 'critical' if likelihood >= 0.8 else 'high' if likelihood >= 0.6 else 'medium'
            }
            
        except Exception as e:
            logger.error(f"Error analyzing exploit complexity: {e}")
            return {}
    
    def _calculate_confidence_score(self, intelligence: Dict) -> float:
        """Calculate confidence score for the intelligence data"""
        score = 0.0
        
        # Base score from data availability
        if intelligence.get('exploit_availability'):
            score += 0.3
        
        if intelligence.get('public_exploits'):
            score += 0.2
        
        if intelligence.get('github_advisories'):
            score += 0.2
        
        if intelligence.get('cisa_kev'):
            score += 0.3
        
        # Bonus for verified exploits
        verified_exploits = [exp for exp in intelligence.get('public_exploits', []) if exp.get('verified')]
        if verified_exploits:
            score += 0.2
        
        return min(score, 1.0)
    
    def _determine_remediation_urgency(self, intelligence: Dict) -> str:
        """Determine remediation urgency based on intelligence"""
        urgency_score = 0
        
        # CISA KEV adds high urgency
        if intelligence.get('cisa_kev'):
            urgency_score += 3
        
        # Public exploits add urgency
        if intelligence.get('exploit_availability'):
            urgency_score += 2
        
        # Verified exploits add more urgency
        verified_exploits = [exp for exp in intelligence.get('public_exploits', []) if exp.get('verified')]
        if verified_exploits:
            urgency_score += 2
        
        # High likelihood adds urgency
        if intelligence.get('exploit_likelihood', 0) >= 0.8:
            urgency_score += 2
        
        # Determine urgency level
        if urgency_score >= 5:
            return 'critical'
        elif urgency_score >= 3:
            return 'high'
        elif urgency_score >= 1:
            return 'medium'
        else:
            return 'low'
    
    async def get_bulk_exploit_intelligence(self, cve_list: List[str]) -> Dict[str, Dict]:
        """
        Get exploit intelligence for multiple CVEs
        
        Args:
            cve_list: List of CVE identifiers
        
        Returns:
            Dict mapping CVE IDs to their intelligence data
        """
        results = {}
        
        # Process CVEs in batches to respect rate limits
        batch_size = 5
        for i in range(0, len(cve_list), batch_size):
            batch = cve_list[i:i + batch_size]
            
            tasks = [self.get_exploit_intelligence(cve_id) for cve_id in batch]
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for j, result in enumerate(batch_results):
                if not isinstance(result, Exception):
                    results[batch[j]] = result
                else:
                    logger.error(f"Error processing {batch[j]}: {result}")
                    results[batch[j]] = {'error': str(result)}
            
            # Rate limiting delay between batches
            if i + batch_size < len(cve_list):
                await asyncio.sleep(2)
        
        return results

# Global exploit intelligence service instance
exploit_intel_service = ExploitIntelligenceService()

